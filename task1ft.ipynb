{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5093016,"sourceType":"datasetVersion","datasetId":2957522}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n!pip install transformers datasets accelerate gradio -q\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:28:55.349528Z","iopub.execute_input":"2025-11-01T18:28:55.349748Z","iopub.status.idle":"2025-11-01T18:30:22.217495Z","shell.execute_reply.started":"2025-11-01T18:28:55.349730Z","shell.execute_reply":"2025-11-01T18:30:22.216530Z"}},"outputs":[{"name":"stdout","text":"Sat Nov  1 18:28:55 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P8             13W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nimport re\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:30:22.218598Z","iopub.execute_input":"2025-11-01T18:30:22.218906Z","iopub.status.idle":"2025-11-01T18:30:23.606642Z","shell.execute_reply.started":"2025-11-01T18:30:22.218875Z","shell.execute_reply":"2025-11-01T18:30:23.606073Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/3a2mext/3A2M_EXTENDED.csv\")\nprint(df.columns)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:30:23.608310Z","iopub.execute_input":"2025-11-01T18:30:23.608632Z","iopub.status.idle":"2025-11-01T18:31:04.672292Z","shell.execute_reply.started":"2025-11-01T18:30:23.608613Z","shell.execute_reply":"2025-11-01T18:31:04.671424Z"}},"outputs":[{"name":"stdout","text":"Index(['title', 'NER', 'Extended_NER', 'genre', 'label', 'directions'], dtype='object')\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                         title  \\\n0                 \\t Arugula Pomegranate Salad   \n1               \\t Black Bean And Turkey Chili   \n2               \\t Finger Lickin' Tofu Nuggets   \n3  \\t Jerk Beef Stew With Carrots And Tomatoes   \n4                \\t Pomegranate Couscous Salad   \n\n                                                 NER  \\\n0  [\"baby spinach\", \"baby arugula\", \"pomegranate ...   \n1  [\"olive oil\", \"yellow onion\", \"garlic\", \"groun...   \n2  [\"extra firm\", \"almond flour\", \"nutritional ye...   \n3  [\"olive oil\", \"boneless beef chuck\", \"onion\", ...   \n4  [\"pomegranate arils\", \"whole wheat couscous\", ...   \n\n                                        Extended_NER       genre  label  \\\n0  ['alfalfa sprouts', 'baby spinach', 'baby arug...  vegetables      4   \n1  ['one', 'yellow onion', 'tomato paste', 'about...       sides      8   \n2  ['extra firm', '2', 'coconut oil', 'almond flo...      nonveg      3   \n3  ['boneless beef chuck', '2', 'Saute', 'onion',...  vegetables      4   \n4  ['whole wheat couscous', '10 minutes', 'lemon ...  vegetables      4   \n\n                                          directions  \n0  [\"Toss together spinach and arugula, then plac...  \n1  [\"Dice the onion and mince the garlic. Add the...  \n2  [\"Wrap the tofu in a clean tea towel and press...  \n3  [\"Preheat oven to 350 degrees F.\", \"Heat the o...  \n4  [\"Place couscous in a bowl with 11/2 cups of h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>NER</th>\n      <th>Extended_NER</th>\n      <th>genre</th>\n      <th>label</th>\n      <th>directions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\t Arugula Pomegranate Salad</td>\n      <td>[\"baby spinach\", \"baby arugula\", \"pomegranate ...</td>\n      <td>['alfalfa sprouts', 'baby spinach', 'baby arug...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Toss together spinach and arugula, then plac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\t Black Bean And Turkey Chili</td>\n      <td>[\"olive oil\", \"yellow onion\", \"garlic\", \"groun...</td>\n      <td>['one', 'yellow onion', 'tomato paste', 'about...</td>\n      <td>sides</td>\n      <td>8</td>\n      <td>[\"Dice the onion and mince the garlic. Add the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\t Finger Lickin' Tofu Nuggets</td>\n      <td>[\"extra firm\", \"almond flour\", \"nutritional ye...</td>\n      <td>['extra firm', '2', 'coconut oil', 'almond flo...</td>\n      <td>nonveg</td>\n      <td>3</td>\n      <td>[\"Wrap the tofu in a clean tea towel and press...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\t Jerk Beef Stew With Carrots And Tomatoes</td>\n      <td>[\"olive oil\", \"boneless beef chuck\", \"onion\", ...</td>\n      <td>['boneless beef chuck', '2', 'Saute', 'onion',...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Preheat oven to 350 degrees F.\", \"Heat the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\t Pomegranate Couscous Salad</td>\n      <td>[\"pomegranate arils\", \"whole wheat couscous\", ...</td>\n      <td>['whole wheat couscous', '10 minutes', 'lemon ...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Place couscous in a bowl with 11/2 cups of h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# ====================================================\n# 1. Basic Cleaning and Column Normalization\n# ====================================================\ndf.columns = df.columns.str.strip().str.lower()\n\n# Remove completely empty rows\ndf.dropna(how='all', inplace=True)\n\n# ====================================================\n# 2. Drop duplicate rows safely (Option 1)\n# ====================================================\ndf_str = df.copy()\nfor col in [\"ner\", \"extended_ner\", \"directions\"]:\n    if col in df_str.columns:\n        df_str[col] = df_str[col].astype(str)  # Convert lists to strings for deduplication\n\ndf = df.loc[~df_str.duplicated()].copy()\nprint(f\"âœ… Duplicates removed, current shape: {df.shape}\")\n\n# ====================================================\n# 3. Clean list-like columns safely\n# ====================================================\ndef clean_list_column(col):\n    cleaned = []\n    for val in col:\n        # Case 1: Already a list/tuple â€” keep it as is\n        if isinstance(val, (list, tuple)):\n            cleaned.append(list(val))\n            continue\n\n        # Case 2: Empty or NaN\n        if pd.isna(val):\n            cleaned.append([])\n            continue\n\n        # Case 3: Try parsing JSON-like strings\n        try:\n            parsed = json.loads(str(val).replace(\"'\", '\"'))\n            if isinstance(parsed, list):\n                cleaned.append(parsed)\n            else:\n                cleaned.append([str(parsed)])\n        except:\n            # Case 4: Fallback to comma-split\n            cleaned.append([x.strip() for x in str(val).split(\",\")])\n    return cleaned\n\n\nfor col in [\"ner\", \"extended_ner\", \"directions\"]:\n    if col in df.columns:\n        df[col] = clean_list_column(df[col])\n\n# Drop rows missing essential data\nif \"title\" in df.columns and \"directions\" in df.columns:\n    df.dropna(subset=[\"title\", \"directions\"], inplace=True)\n\nprint(f\"âœ… After cleaning list-like columns: {df.shape}\")\n\n# ====================================================\n# 4. Skip Genre Normalization (as requested)\n# ====================================================\nif \"genre\" not in df.columns:\n    df[\"genre\"] = \"unknown\"\n\n# ====================================================\n# 5. Add Derived Columns\n# ====================================================\ndf[\"ingredient_count\"] = df[\"ner\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\ndf[\"direction_length\"] = df[\"directions\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n\n# Remove rows with no ingredients or directions\ndf = df[(df[\"ingredient_count\"] > 0) & (df[\"direction_length\"] > 0)]\n\n# Drop duplicates based on title + genre\ndf.drop_duplicates(subset=[\"title\", \"genre\"], inplace=True)\n\n# Reset index\ndf.reset_index(drop=True, inplace=True)\n\nprint(f\"âœ… Final cleaned dataset shape: {df.shape}\")\n\n# ====================================================\n# 6. Display Random Samples\n# ====================================================\nprint(\"\\n=== Random Sample of Cleaned Recipes ===\\n\")\nsample_df = df.sample(min(10, len(df)), random_state=42)[[\"title\", \"genre\", \"ner\", \"directions\"]]\n\nfor i, row in sample_df.iterrows():\n    print(f\"Recipe {i+1}: {row['title']}\")\n    print(f\"Genre: {row['genre']}\")\n    print(f\"Ingredients ({len(row['ner'])}): {', '.join(row['ner'][:10])}...\")\n    print(f\"First 2 Steps: {row['directions'][:2]}\")\n    print(\"-\" * 100)\n\n# ====================================================\n# 7. Summary Stats\n# ====================================================\nprint(\"\\n=== Dataset Statistics ===\")\nprint(f\"Average number of ingredients: {df['ingredient_count'].mean():.2f}\")\nprint(f\"Average number of directions: {df['direction_length'].mean():.2f}\")\nprint(f\"Unique genres: {df['genre'].nunique()} -> {sorted(df['genre'].unique().tolist())}\")\n\n# ====================================================\n# 8. Save Cleaned CSV\n# ====================================================\noutput_path = \"cleaned_recipes.csv\"\ndf.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\nprint(f\"\\nâœ… Cleaned dataset saved as: {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:31:04.673385Z","iopub.execute_input":"2025-11-01T18:31:04.673987Z","iopub.status.idle":"2025-11-01T18:32:55.975242Z","shell.execute_reply.started":"2025-11-01T18:31:04.673953Z","shell.execute_reply":"2025-11-01T18:32:55.974429Z"}},"outputs":[{"name":"stdout","text":"âœ… Duplicates removed, current shape: (2230998, 6)\nâœ… After cleaning list-like columns: (2230997, 6)\nâœ… Final cleaned dataset shape: (1314993, 8)\n\n=== Random Sample of Cleaned Recipes ===\n\nRecipe 622937: Honey-Dijon Salad with Shrimp\nGenre: vegetables\nIngredients (11): [\"torn romaine lettuce leaves\", \"shrimp\", \"mushrooms\", \"carrots\", \"egg substitute\", \"corn oil\", \"white wine vinegar\", \"Mustard\", \"honey\", \"croutons\"...\nFirst 2 Steps: ['[\"Mix lettuce', 'shrimp']\n----------------------------------------------------------------------------------------------------\nRecipe 666671: Kaessuppe\nGenre: fusion\nIngredients (7): [\"butter\", \"flour\", \"emmentaler cheese\", \"beef stock\", \"egg yolks\", \"sugar\", \"bread\"]...\nFirst 2 Steps: ['[\"Melt the butter and stir in the flour.\"', '\"Add meat broth.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 284614: Chimichurri Muy Perfecto\nGenre: fusion\nIngredients (10): [\"flat-leaf Italian parsley\", \"olive oil\", \"red wine vinegar\", \"oregano\", \"ground cumin\", \"kosher salt\", \"garlic\", \"hot sauce\", \"red pepper\", \"lemon juice\"]...\nFirst 2 Steps: ['[\"Combine all ingredients in a food processor', 'and process until the parsley is finely minced.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 824173: None Such Cinnamon Raisin Biscotti\nGenre: sides\nIngredients (8): [\"sugar\", \"butter\", \"eggs\", \"vanilla\", \"flour\", \"baking powder\", \"ground cinnamon\", \"condensed mincemeat\"]...\nFirst 2 Steps: ['[\"Preheat oven to 325 degrees F. In large bowl', 'beat sugar']\n----------------------------------------------------------------------------------------------------\nRecipe 40233: Apple Cider Chicken With Wild Rice\nGenre: sides\nIngredients (15): [\"Chicken\", \"skinless\", \"salt\", \"canola oil\", \"shallots\", \"apple cider vinegar\", \"sweet apple cider\", \"apple\", \"sweet apple\", \"chicken broth\"...\nFirst 2 Steps: ['[\"Season chicken cutlets with salt and pepper.\"', '\"Get a skillet very hot. Once it is hot']\n----------------------------------------------------------------------------------------------------\nRecipe 1235434: Trout Kottwitz\nGenre: Fusion\nIngredients (9): [\"butter\", \"trout\", \"artichoke bottoms\", \"mushrooms\", \"salt\", \"pepper\", \"Brown Sauce\", \"lemon juice\", \"butter\"]...\nFirst 2 Steps: ['Melt 5 tablespoons butter in a large heavy skillet add trout artichokes and mushrooms and cook 7 to 8 minutes over medium heat or until fish flakes easily with a fork. Sprinkle with salt and pepper while cooking. Remove fish and vegetables to heated plates or keep warm in low oven. Combine Brown Sauce lemon juice and the 2 cups butter mix with a wire whisk and cook over low heat until heated through. To serve ladle about 1/4 cup sauce over each fillet. Makes 8 servings.']\n----------------------------------------------------------------------------------------------------\nRecipe 1024441: Salmon With A Lemon Teriyaki Glaze\nGenre: drinks\nIngredients (8): [\"soy sauce\", \"sugar\", \"rice wine\", \"garlic\", \"ginger\", \"lemon\", \"mustard\", \"salmon\"]...\nFirst 2 Steps: ['[\"In a pot', 'combine the soy sauce']\n----------------------------------------------------------------------------------------------------\nRecipe 1249204: Ukrainian Fruit Vodka (Varenukha)\nGenre: vegetables\nIngredients (11): [\"dried apples\", \"cherries\", \"pear\", \"vodka\", \"honey\", \"ground ginger\", \"ground cinnamon\", \"ground cloves\", \"black pepper\", \"bay leaf\"...\nFirst 2 Steps: ['[\"Place each of the four fruits in a separate bowl.\"', '\"Cover the fruits with the vodka.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 831210: Oatmeal Cookies With White Chocolate Chips and Raisins\nGenre: cereal\nIngredients (12): [\"unsalted butter\", \"sugar\", \"brown sugar\", \"egg\", \"vanilla\", \"flour\", \"rolled oats\", \"baking soda\", \"cinnamon\", \"salt\"...\nFirst 2 Steps: ['[\"Beat the butter', 'granulated sugar and brown sugar in a bowl with a mixer on medium speed until fluffy.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 415643: Dill Meatballs With Cranberry Sauce\nGenre: sides\nIngredients (16): [\"butter\", \"shallot\", \"frozen cranberries\", \"brown sugar\", \"cranberry juice\", \"rosemary\", \"red wine vinegar\", \"cornstarch\", \"sour cream\", \"milk\"...\nFirst 2 Steps: ['[\"Melt the butter in a saucepan over medium-low heat. Add the shallot and cook for 2-3 mins until softened. Add the cranberries and brown sugar and cook for 7-10 mins until the cranberries begin to pop. Stir in the cranberry juice', 'rosemary and vinegar. In a cup']\n----------------------------------------------------------------------------------------------------\n\n=== Dataset Statistics ===\nAverage number of ingredients: 8.93\nAverage number of directions: 12.84\nUnique genres: 10 -> ['Fusion', 'bakery', 'cereal', 'drinks', 'fastfood', 'fusion', 'meal', 'nonveg', 'sides', 'vegetables']\n\nâœ… Cleaned dataset saved as: cleaned_recipes.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport ast\nimport re\n\n# --- Robust cleaning function ---\ndef clean_recipe(row):\n    # --- Helper to remove brackets, quotes, and fix unicode ---\n    def clean_text(text):\n        if not text:\n            return \"\"\n        text = str(text)\n        # Fix degree/Fahrenheit symbols\n        text = text.replace(\"\\\\u00b0\", \"Â°\")  # Unicode Â° symbol\n        text = text.replace(\"\\\\u00b0F\", \"Â°F\")\n        text = text.replace(\"\\\\u00b0C\", \"Â°C\")\n        # Remove all [ ] { } ' \" ` and extra spaces\n        text = re.sub(r\"[\\[\\]{}'\\\"`]\", \"\", text)\n        text = re.sub(r\"\\s+\", \" \", text)\n        return text.strip()\n\n    # --- Ingredients ---\n    ner_val = row.get(\"ner\", [])\n    if isinstance(ner_val, str):\n        try:\n            ner_val = ast.literal_eval(ner_val)\n        except:\n            ner_val = [ner_val]\n    ingredients = \", \".join([clean_text(i) for i in ner_val if str(i).strip()])\n\n    # --- Directions ---\n    dir_val = row.get(\"directions\", [])\n    if isinstance(dir_val, str):\n        try:\n            dir_val = ast.literal_eval(dir_val)\n        except:\n            dir_val = [dir_val]\n    # Flatten nested lists\n    flat_dirs = []\n    for d in dir_val:\n        if isinstance(d, (list, tuple)):\n            flat_dirs.extend(d)\n        else:\n            flat_dirs.append(d)\n    directions = \" \".join([clean_text(d) for d in flat_dirs if str(d).strip()])\n\n    # --- Title ---\n    title = clean_text(row.get(\"title\", \"\"))\n\n    # --- Compose final recipe ---\n    return f\"<|startofrecipe|> Title: {title}\\nIngredients: {ingredients}\\nDirections: {directions} <|endofrecipe|>\"\n\n# --- Apply cleaning ---\ndf['text'] = df.apply(clean_recipe, axis=1)\n\n# --- Remove duplicates ---\ndf.drop_duplicates(subset='text', inplace=True)\n\n# --- Check remaining brackets ---\nremaining_brackets = df['text'].str.contains(r'[\\[\\]]').sum()\nprint(f\"Remaining brackets: {remaining_brackets}\")  # Should be 0\n\n# --- Show first 15 examples ---\nfor i in range(min(15, len(df))):\n    print(f\"Example {i+1}:\\n{df['text'].iloc[i]}\\n{'-'*80}\")\n\n# --- Save cleaned dataset to CSV ---\noutput_path = \"cleaned_recipes_final.csv\"\ndf.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\nprint(f\"\\nâœ… Cleaned dataset saved as: {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:32:55.976248Z","iopub.execute_input":"2025-11-01T18:32:55.976551Z","iopub.status.idle":"2025-11-01T18:36:36.754085Z","shell.execute_reply.started":"2025-11-01T18:32:55.976526Z","shell.execute_reply":"2025-11-01T18:36:36.753385Z"}},"outputs":[{"name":"stdout","text":"Remaining brackets: 0\nExample 1:\n<|startofrecipe|> Title: Arugula Pomegranate Salad\nIngredients: baby spinach, baby arugula, pomegranate arils, persimmon, alfalfa sprouts\nDirections: Toss together spinach and arugula then place in your serving bowl. Remove the stem and leaves of the persimmon then slice into thin wedges. Arrange the persimmon on top of the spinach and arugula. Garnish with pomegranate arils and alfalfa sprouts. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 2:\n<|startofrecipe|> Title: Black Bean And Turkey Chili\nIngredients: olive oil, yellow onion, garlic, ground turkey, black beans, tomatoes, tomato paste, chili powder, cumin, paprika, oregano, salt\nDirections: Dice the onion and mince the garlic. Add the onion and garlic to a large stock pot with one tablespoon of olive oil and cook over medium-low heat just until softened. Add the ground turkey to the pot and continue to saute until the turkey is cooked through. Break the turkey up into small crumbles as it cooks. Add the all of the remaining ingredients. Stir to combine. Let the chili simmer for about 10 minutes to let the flavors blend and help the liquid thicken slightly. Add salt to taste. Enjoy with your favorite chili toppings! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 3:\n<|startofrecipe|> Title: Finger Lickin Tofu Nuggets\nIngredients: extra firm, almond flour, nutritional yeast, garlic, unsweetened almond milk, coconut oil\nDirections: Wrap the tofu in a clean tea towel and press to remove excess water. Combine all other ingredients in a bowl except for the almond milk. Slowly add the almond milk and stir until you get a paste. Cut the tofu into bite-sized pieces. You can do strips or nuggets if you like but the smaller bites mean more of the yummy coating. Plus it reminds me of popcorn shrimp or chicken! Roll the tofu bites around in the coating until theyre well... coated. Over medium heat heat the oil in a frying pan. Add tofu bites in a single layer and brown them on 2 sides. Serve with Sriracha or other favourite dipping sauce. Enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 4:\n<|startofrecipe|> Title: Jerk Beef Stew With Carrots And Tomatoes\nIngredients: olive oil, boneless beef chuck, onion, Progresso, jerk sauce, allspice, cinnamon, thyme, brown rice\nDirections: Preheat oven to 350 degrees F. Heat the olive oil in a Dutch oven over medium-high heat. Add the beef and let it brown on each side (about 5 minutes/side). Stir the beef and add the onions carrots and garlic. Saute for 3 minutes or until the onions are translucent. Cover the Dutch oven and place it in the oven. Cook for 1 hour to 1 1/2 hours or until the beef falls apart easily when shredded 2 forks. Take the stew out of the oven. Remove the bay leaves. If the stew is too thin reduce over high heat on the stovetop. Serve over the brown rice or quinoa and with a side of greens. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 5:\n<|startofrecipe|> Title: Pomegranate Couscous Salad\nIngredients: pomegranate arils, whole wheat couscous, extra virgin olive oil, cilantro, cranberries, lemon juice\nDirections: Place couscous in a bowl with 11/2 cups of hot water. Cover bowl with plastic wrap and let set for 10 minutes. Add the olive oil and toss gently. Add vegetables and cilantro or parsley; mix to combine. Add cranberries arils and lemon juice; salt and pepper to taste. Gently toss and enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 6:\n<|startofrecipe|> Title: Raclette Hasselback Potatoes\nIngredients: potatoes, olive oil, butter, salt Generous, raclette cheese, paprika\nDirections: Preheat oven to 425Â°F (220Â°C). Melt the butter in a small saucepan and pour it in a large bowl. Mix with the olive oil and season with salt pepper ground coriander seeds dry aromatic herbs ... Cut the potatoes into thin slices without completely detaching those slices from the potato so that they stay tied together. Baste the potatoes one by one with the butter and olive oil mixture opening gently each slice so that the fat gets between each and place them in a large oven dish. First bake the potatoes for 30 minutes. Then take the dish out of the oven and coat the potatoes with the cooking sauce or the rest of the butter and olive oil mixture. Bake the potatoes for 45 more minutes until they are golden tender and opened. In the meantime cut the raclette cheese into pieces small enough to be placed between each slice of the potatoes. Take out the dish from the oven when the potatoes are cooked and place the pieces of cheese between each slice of the potatoes until there is no more. If you want you can alternate the pieces of cheese with other ingredients such as ham pepper broccoli or any other ingredient you fancy. Place the dish with the stuffed potatoes in oven on \\grill\\ mode and bake for 5 more minutes. Add more seasoning if you like: paprika aromatic herbs ... and serve very hot. Eaten with a salad or as a side dish with a meat these potatoes are delicious.\\n\\nBon appetit! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 7:\n<|startofrecipe|> Title: The Black Pear Shim\nIngredients: Black Balsam, Juice(I, Lemon Juice, Syrup\nDirections: Shake all ingredients to chill and dilute. Strain into a martini glass and garnish with a lemon twist. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 8:\n<|startofrecipe|> Title: Mixed Mashed Muffins\nIngredients: butter, egg, brown sugar, honey crunch peanut butter, vanilla, baking soda, granola Kimberly, water\nDirections: Combine flour brown sugar salt and baking soda and Kimberlys Granola in large bowl set aside. Cream together egg vanilla peanut butter milk or water until smooth. Gradually add soft mixture to flour brown sugar salt baking soda and Kimberlys Granola until totally combined. Spoon into muffin tin and bake in preheated 350 degree oven for 20-25 minutes Remove from oven and remove from muffin tin to cool on cooling rack. Serve warm and Enjoy! <3 <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 9:\n<|startofrecipe|> Title: Penut Butter Fudge Delight\nIngredients: white sugar, milk, vanilla, butter, milk, butter\nDirections: In a medium saucepan over medium heat combine sugar butter and milk. Bring to a boil. stir and boil for 7 minutes. remove from sauce pan and add peanut butter and vanilla extract if not melting put back on stove and bring to a low boil grease a 9 bt 13 baking dish pour into the dish and voila leave over night and cut into cubes enjoy !!!!!!!!!!!!!!!!!!! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 10:\n<|startofrecipe|> Title: Kevinâ€™S Insane Bacon Cheese Dip\nIngredients: bacon, cream cheese, mayo, swiss cheese, cheddar cheese, green onion, butter crackers\nDirections: Cook bacon. Drain crumble. Mix the cream cheese with mayo until smooth. Stir in Swiss & Cheddar cheese onions and bacon. Place bowl in microwave and cook 2 minutes. Pull it out and stir it up good. Microwave another 2 or 3 minutes more. Sprinkle crushed crackers on top. Serve it up warm with crackers! (Yep... yet another one that I stole off the net... but severely modified it!!!) <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 11:\n<|startofrecipe|> Title: ~Raspberry Butterfly Cupcakes~\nIngredients: sugar, margarine, eggs, flour, tspbaking power, vanilla, raspberry\nDirections: Preheat the oven to 190*c/375*F/ Gas Mark 5. line one or two bun trays with 12-14 cases depending on the depth of the holes. Places all the cupcake ingredients in a large bowl and beat with the electric mixer for about 2 minutes until smooth. Fill the paper cases halfway up the mixture. Bake for about 15 minutes until firm risen and golden. Remove to a wire rack and cool it. When its cool cut a small circle out of the top of each cupcake and then cut the circles in half like a wings shape. Fill each cupcake with a teaspoon of raspberry jam. replace the wings at an angle and top each with a fresh reaspberry. dust lightly with icing sugar and serve immediately. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 12:\n<|startofrecipe|> Title: Bacon Lovers Ranch Mashed Potatoes\nIngredients: potatoes, butter, mayo, sour cream, bacon Party\nDirections: : In a pot cube desired amount of potatoes or use instant potatoes. Cook until the potatoes are tender drain and then mash. Add 1/2 cup butter 3 tbs. mayonnaise 1 cup sour cream and 1 package dip mix. Whip the added ingredients into the cooked/mashed potatoes. Serve and enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 13:\n<|startofrecipe|> Title: 20-Minute Kale And Quinoa Bowl\nIngredients: water, quinoa, kale washed, lemon, scallions, olive oil, almonds, goat cheese, salt\nDirections: Bring 2 cups water to boil in a covered pot with a large pinch of salt. Add quinoa lower heat to simmer cover and simmer 10 minutes. After 8-10 minutes when theres still some water left add the chopped kale... Cover let simmer for 5 minutes then turn off the heat and let it sit for 5 minutes covered. Combine half of lemon juice with zest scallions olive oil nuts and cheese into a bowl Put quinoa kale mixture in a bowl. add one bowl to another and mix. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 14:\n<|startofrecipe|> Title: Busy Morning Corn Muffins\nIngredients: flour, cornmeal, sugar, salt, baking powder, milk regular, butter, eggs\nDirections: Equipment youll need ready:\\n\\n2 bowls (1 for dry 1 for wet)\\nliquid and dry measure cups\\nmeasuring spoons\\nmuffin tins to make 12 regular sized muffins (not the huge muffin tins)\\ncooling rack\\nwhisk (if you have one)\\nwooden spoon\\nrubber spatula\\ncupcake papers (or grease the muffin tin very well)\\n\\nPreheat oven to 500Â° Bowl 1 - Dry:\\n\\nMix flour cornmeal sugar salt and baking powder whisking till all ingredient are completely mixed so ingredients are evenly dispersed. I love using the whisk for this. Bowl 2 -Wet:\\n\\nThoroughly blend eggs milk and oil together. Add wet to dry bowl just mix well enough so nothing is dry sticking to the sides of the bowl but dont beat. Use a scraper of wooden spoon to mix thoroughly - over mixing (no electric beaters please) will make for tough muffins! Evenly fill the muffin tins. Using a scoop* helps with aim into the cup part or even a dry measure 1/2 cup size would be beneficial so they are all the same size which makes for nicer presentation and more even baking. Note: I find it easier to wipe batter that didnt make it into the cups before baking is easier than scrubbing it off later. Pop the tin into the oven and as soon as you close the door LOWER the oven temperature to 400Â° bake 18-20 minutes. This super hot then lower method will allow the muffins get that nice domed look. Cool on a wire rack for a few minutes. Enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 15:\n<|startofrecipe|> Title: Oatmeal\nIngredients: Oats, water, milk, cinnamon, put\nDirections: cook it for 15 or 20 minutes get it out <|endofrecipe|>\n--------------------------------------------------------------------------------\n\nâœ… Cleaned dataset saved as: cleaned_recipes_final.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Check if any brackets remain\ndf['text'].str.contains(r'[\\[\\]]').sum()  # Should be 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:36:36.754806Z","iopub.execute_input":"2025-11-01T18:36:36.755015Z","iopub.status.idle":"2025-11-01T18:36:45.584541Z","shell.execute_reply.started":"2025-11-01T18:36:36.754997Z","shell.execute_reply":"2025-11-01T18:36:45.583907Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# one-time installs (run in a notebook cell)\n!pip install -q transformers datasets accelerate bitsandbytes peft evaluate sentencepiece gradio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T18:36:45.585228Z","iopub.execute_input":"2025-11-01T18:36:45.585441Z","iopub.status.idle":"2025-11-01T18:36:52.551977Z","shell.execute_reply.started":"2025-11-01T18:36:45.585424Z","shell.execute_reply":"2025-11-01T18:36:52.551116Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ==========================================================\n#  DISTILGPT2 RECIPE FINE-TUNING (LoRA + 4-bit + Tokenizer Integration)\n# ==========================================================\nimport os, gc, random\nimport pandas as pd\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    AutoConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\n\n# ---------------- CONFIG ----------------\nMODEL_NAME = \"distilgpt2\"      # smaller + faster than GPT-2\nCLEANED_CSV = \"cleaned_recipes_final.csv\"\nOUTPUT_DIR = \"/kaggle/working/gpt2_recipe_lora\"\nNUM_EPOCHS = 3                 # 3â€“5 sufficient per assignment\nPER_DEVICE_BATCH = 2\nGRAD_ACCUM = 8\nMAX_LENGTH = 512\nSEED = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\">>> Device: {DEVICE}\")\n\n# ---------------- REPRODUCIBILITY ----------------\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\nif DEVICE == \"cuda\":\n    torch.cuda.manual_seed_all(SEED)\n\n# ---------------- LOAD DATA ----------------\ndf = pd.read_csv(CLEANED_CSV, encoding=\"utf-8-sig\")\ndf = df[[\"text\"]].dropna().reset_index(drop=True)\nprint(\"Loaded samples:\", len(df))\n\ndataset = Dataset.from_pandas(df)\n\n# ---------------- TOKENIZER ----------------\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\nspecial_tokens = [\"<|startofrecipe|>\", \"<|endofrecipe|>\"]\ntokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\ntokenizer.pad_token = tokenizer.eos_token  # GPT2 has no pad token\n\ndef tokenize_batch(examples):\n    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH)\n\nprint(\"Tokenizing dataset...\")\ndataset = dataset.map(tokenize_batch, batched=True, remove_columns=[\"text\"], desc=\"Tokenizing\")\ndataset = dataset.train_test_split(test_size=0.1, seed=SEED)\ntrain_ds = dataset[\"train\"]\neval_ds  = dataset[\"test\"]\nprint(f\"Train size: {len(train_ds)}  |  Eval size: {len(eval_ds)}\")\n\n# ---------------- MODEL (4-BIT LOAD) ----------------\nload_4bit = torch.cuda.is_available()\nif load_4bit:\n    print(\">>> Using 4-bit quantization for efficiency\")\n    from transformers import BitsAndBytesConfig\n    quant_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\"\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n        MODEL_NAME,\n        device_map=\"auto\",\n        quantization_config=quant_config\n    )\nelse:\n    print(\">>> Loading model normally (no 4-bit support detected)\")\n    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n\n# Resize embeddings for special tokens\ntry:\n    model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\nexcept TypeError:\n    model.resize_token_embeddings(len(tokenizer))\n\n# ---------------- APPLY LORA ----------------\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"c_attn\", \"q_proj\", \"v_proj\"]\n)\nmodel = get_peft_model(model, peft_config)\n\n# Freeze non-LoRA params\nfor n, p in model.named_parameters():\n    if \"lora\" not in n:\n        p.requires_grad = False\n\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\">>> Trainable params: {trainable_params:,} / {total_params:,}\")\n\n# ---------------- DATA COLLATOR ----------------\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n# ---------------- TRAINING ARGS ----------------\ntry:\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        num_train_epochs=NUM_EPOCHS,\n        per_device_train_batch_size=PER_DEVICE_BATCH,\n        per_device_eval_batch_size=PER_DEVICE_BATCH,\n        gradient_accumulation_steps=GRAD_ACCUM,\n        fp16=True,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        logging_strategy=\"steps\",\n        logging_steps=50,\n        learning_rate=5e-5,\n        weight_decay=0.01,\n        warmup_steps=50,\n        save_total_limit=2,\n        report_to=\"none\",\n        dataloader_num_workers=2,\n        optim=\"paged_adamw_32bit\"\n    )\n    print(\">>> TrainingArguments initialized successfully.\")\nexcept TypeError:\n    print(\">>> Transformer version fallback detected.\")\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        num_train_epochs=NUM_EPOCHS,\n        per_device_train_batch_size=PER_DEVICE_BATCH,\n        gradient_accumulation_steps=GRAD_ACCUM,\n        fp16=True,\n        logging_steps=50,\n        save_steps=500,\n        learning_rate=5e-5,\n        weight_decay=0.01,\n        warmup_steps=50,\n        report_to=\"none\"\n    )\n\n# ---------------- TRAINER ----------------\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\n# ---------------- TRAINING ----------------\nprint(\"\\n>>> Starting fine-tuning for\", NUM_EPOCHS, \"epochs...\")\ntrainer.train()\nprint(\">>> Training complete âœ…\")\n\n# ---------------- SAVE MODEL ----------------\ntrainer.save_model(os.path.join(OUTPUT_DIR, \"final_checkpoint\"))\nmodel.save_pretrained(os.path.join(OUTPUT_DIR, \"lora_adapter\"))\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(\">>> Model + tokenizer saved to\", OUTPUT_DIR)\n\n# ---------------- GENERATE SAMPLE OUTPUT ----------------\nprint(\"\\n>>> Generating sample recipe for qualitative evaluation...\")\nprompt = \"<|startofrecipe|> Title: Creamy Mushroom Pasta\\nIngredients: mushroom, cream, garlic, pasta\\nDirections:\"\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n\ngeneration = model.generate(\n    input_ids,\n    max_length=200,\n    do_sample=True,\n    top_k=50,\n    top_p=0.95,\n    temperature=0.8,\n    num_return_sequences=1\n)\n\nprint(\"\\n=== SAMPLE GENERATION ===\\n\")\nprint(tokenizer.decode(generation[0], skip_special_tokens=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================================================\n#  GENERATE SAMPLE RECIPES FROM LoRA + 4-BIT CHECKPOINT (FIXED)\n# ==========================================================\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\n\n# ---------- PATHS ----------\nBASE_MODEL = \"distilgpt2\"\nCHECKPOINT_DIR = \"/kaggle/working/gpt2_recipe_lora/checkpoint-10000\"\n\n# ---------- DEVICE ----------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\">>> Using device: {DEVICE}\")\n\n# ---------- LOAD TOKENIZER ----------\ntokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_DIR)\ntokenizer.pad_token = tokenizer.eos_token\n\n# ---------- LOAD BASE MODEL ----------\nprint(\">>> Loading base model...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n    device_map=\"auto\"\n)\n\n# ğŸš¨ Resize embeddings to match tokenizer (important fix)\nbase_model.resize_token_embeddings(len(tokenizer))\n\n# ---------- LOAD LoRA ADAPTER ----------\nprint(\">>> Loading fine-tuned LoRA adapter...\")\nmodel = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR)\nmodel = model.to(DEVICE)\nmodel.eval()\n\n# ---------- SAMPLE PROMPTS ----------\nprompts = [\n    \"<|startofrecipe|> Title: Creamy Mushroom Pasta\\nIngredients: mushroom, cream, garlic, pasta\\nDirections:\",\n    \"<|startofrecipe|> Title: Spicy Chicken Curry\\nIngredients: chicken, chili, onion, tomato, garlic\\nDirections:\",\n    \"<|startofrecipe|> Title: Chocolate Chip Cookies\\nIngredients: flour, sugar, butter, chocolate chips\\nDirections:\",\n    \"<|startofrecipe|> Title: Fresh Lemonade\\nIngredients: lemon, sugar, water, ice\\nDirections:\"\n]\n\n# ---------- GENERATION SETTINGS ----------\ngen_kwargs = dict(\n    max_new_tokens=150,\n    do_sample=True,\n    temperature=0.8,\n    top_p=0.95,\n    top_k=50,\n    pad_token_id=tokenizer.eos_token_id,\n)\n\n# ---------- GENERATE ----------\nprint(\"\\n>>> Generating sample recipes...\\n\")\nfor prompt in prompts:\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n    outputs = model.generate(input_ids, **gen_kwargs)\n    print(\"=\" * 70)\n    print(f\"Prompt:\\n{prompt}\\n\")\n    print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n    print(\"=\" * 70, \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T21:12:54.043495Z","iopub.execute_input":"2025-11-01T21:12:54.044195Z","iopub.status.idle":"2025-11-01T21:12:59.964413Z","shell.execute_reply.started":"2025-11-01T21:12:54.044167Z","shell.execute_reply":"2025-11-01T21:12:59.963589Z"}},"outputs":[{"name":"stdout","text":">>> Using device: cuda\n>>> Loading base model...\n>>> Loading fine-tuned LoRA adapter...\n\n>>> Generating sample recipes...\n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Creamy Mushroom Pasta\nIngredients: mushroom, cream, garlic, pasta\nDirections:\n\n<|startofrecipe|> Title: Creamy Mushroom Pasta\nIngredients: mushroom, cream, garlic, pasta\nDirections: Preheat oven to 375. Mix mushrooms and cream in. Sprinkle cheese in mushrooms. Sprinkle with eggplant mixture and cream. Mix well. Sprinkle with cheese. <|endofrecipe|> Creamy Mushroom Pasta <|endofrecipe|> lightly with cream and garlic. <|endofrecipe|> 8x10cm on parchment paper. <|endofrecipe|> Creamy Mushroom Pasta <|endofrecipe|> with cream and garlic. <|endofrecipe|> 2 minutes <|endofrecipe|> Cold cream <|endofrecipe|> Cold cream  <|endofrecipe|>                                                             \n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Spicy Chicken Curry\nIngredients: chicken, chili, onion, tomato, garlic\nDirections:\n\n<|startofrecipe|> Title: Spicy Chicken Curry\nIngredients: chicken, chili, onion, tomato, garlic\nDirections: Stir in chicken and chili. Put in chicken and chili. Bring to a boil. Stir in onion tomato garlic and cook until golden brown. Stir in onion and tomato. Let cool for about 30 minutes. Stir in tomato and garlic. Serve. <|endofrecipe|> 5 times. <|endofrecipe|> 5 times. <|endofrecipe|> 2 times. <|endofrecipe|> <|endofrecipe|> <|endofrecipe|> <|endofrecipe|> <|endofrecipe|> <|endofrecipe|> <|endofrecipe|>  <|endofrecipe|>                                                                     \n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Chocolate Chip Cookies\nIngredients: flour, sugar, butter, chocolate chips\nDirections:\n\n<|startofrecipe|> Title: Chocolate Chip Cookies\nIngredients: flour, sugar, butter, chocolate chips\nDirections: In a large bowl combine flour sugar and chocolate chips. Mix well. Add chocolate chips. Cover well. Pour into the cookie tin and bake at 350 degrees until sugar is incorporated. <|endofrecipe|> on high with butter and butter and let cool for 1 hour or until a cookie is set at 350 degrees. <|endofrecipe|> all on top of cookie. <|endofrecipe|> cookies with chocolate chips <|endofrecipe|> cookies <|endofrecipe|> Cookie Tossed with sugar and butter. <|endofrecipe|> all on top of cookie. <|endofrecipe|> all on top of cookie. <|endofrecipe|> all on top of cookie. <|endofrecipe|> all on top of cookie. <|endofrecipe|> all on top of cookie. <|endofrecipe|> all on top of cookie.  <|endofrecipe|> all on top of cookie.  <|endofrecipe|> all on\n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Fresh Lemonade\nIngredients: lemon, sugar, water, ice\nDirections:\n\n<|startofrecipe|> Title: Fresh Lemonade\nIngredients: lemon, sugar, water, ice\nDirections: Mix well. In a large bowl combine lemon juice sugar water ice and ice. Add ice and refrigerate until chilled. <|endofrecipe|> Ice can be made easily by adding ice or by mixing in ice. <|endofrecipe|> Can be made with a hand mixer. <|endofrecipe|> 4 different types of lemonade <|endofrecipe|> is pretty easy. <|endofrecipe|> 3 of the lemonade can be made using a stick or an 8mm stick. <|endofrecipe|> can be made with a stick or an 8mm stick. <|endofrecipe|> the frozen lemonade can be made with a stick or an 8mm stick. <|endofrecipe|> 3 of the lemonade can be made using a stick or an 8mm stick. <|endofrecipe|> 2-3 lemonade can be made with a stick or an 8\n====================================================================== \n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ==========================================================\n# ğŸ³ Gradio App for LoRA-Finetuned DistilGPT2 (Recipe Generator)\n# ==========================================================\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nimport gradio as gr\n\n# ---------- Paths ----------\nBASE_MODEL = \"distilgpt2\"\nCHECKPOINT_DIR = \"/kaggle/working/gpt2_recipe_lora/checkpoint-10000\"  # your LoRA adapter path\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---------- Load Tokenizer ----------\nprint(\">>> Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\nspecial_tokens = {\n    \"pad_token\": \"<|pad|>\",\n    \"bos_token\": \"<|startofrecipe|>\",\n    \"eos_token\": \"<|endofrecipe|>\"\n}\ntokenizer.add_special_tokens(special_tokens)\n\n# ---------- Load Base Model ----------\nprint(\">>> Loading base model...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n)\nbase_model.resize_token_embeddings(len(tokenizer))\n\n# ---------- Load LoRA Adapter ----------\nprint(\">>> Loading LoRA fine-tuned adapter...\")\ntry:\n    model = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR)\n    print(\"âœ… LoRA adapter loaded successfully!\")\nexcept Exception as e:\n    print(f\"âš ï¸ Adapter load issue: {e}\")\n    print(\"Retrying with ignore_mismatched_sizes=True ...\")\n    model = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR, ignore_mismatched_sizes=True)\n\nmodel = model.to(DEVICE)\nmodel.eval()\n\nprint(\"âœ… Model ready for generation!\")\n\n# ---------- Generation Function ----------\ndef generate_recipe(title, ingredients, max_length=200, temperature=0.8, top_p=0.9):\n    prompt = f\"<|startofrecipe|> Title: {title}\\nIngredients: {ingredients}\\nDirections:\"\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            max_length=max_length,\n            do_sample=True,\n            temperature=temperature,\n            top_p=top_p,\n            pad_token_id=tokenizer.eos_token_id\n        )\n\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    recipe = generated_text.replace(prompt, \"\").strip()\n    return recipe\n\n# ---------- Gradio Interface ----------\ndemo = gr.Interface(\n    fn=generate_recipe,\n    inputs=[\n        gr.Textbox(label=\"Recipe Title\", placeholder=\"Creamy Mushroom Pasta\"),\n        gr.Textbox(label=\"Ingredients (comma-separated)\", placeholder=\"mushroom, cream, garlic, pasta\"),\n        gr.Slider(50, 400, value=200, step=10, label=\"Max Length\"),\n        gr.Slider(0.5, 1.2, value=0.8, step=0.05, label=\"Temperature\"),\n        gr.Slider(0.6, 1.0, value=0.9, step=0.05, label=\"Top-p\"),\n    ],\n    outputs=gr.Textbox(label=\"Generated Recipe Directions\"),\n    title=\"ğŸ³ LoRA-Finetuned Recipe Generator\",\n    description=\"Generate creative cooking directions using a LoRA-finetuned DistilGPT2 model.\",\n    examples=[\n        [\"Garlic Butter Shrimp\", \"shrimp, garlic, butter, lemon, parsley\"],\n        [\"Pancakes\", \"flour, milk, egg, sugar, butter, baking powder\"],\n        [\"Spaghetti Aglio e Olio\", \"spaghetti, garlic, olive oil, chili flakes, parsley\"]\n    ]\n)\n\ndemo.launch(debug=True, share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T21:58:13.184590Z","iopub.execute_input":"2025-11-01T21:58:13.185120Z","execution_failed":"2025-11-01T23:45:28.226Z"}},"outputs":[{"name":"stdout","text":">>> Loading tokenizer...\n>>> Loading base model...\n>>> Loading LoRA fine-tuned adapter...\nâš ï¸ Adapter load issue: Error(s) in loading state_dict for PeftModelForCausalLM:\n\tsize mismatch for base_model.model.transformer.wte.weight: copying a param with shape torch.Size([50259, 768]) from checkpoint, the shape in current model is torch.Size([50260, 768]).\n\tsize mismatch for base_model.model.lm_head.weight: copying a param with shape torch.Size([50259, 768]) from checkpoint, the shape in current model is torch.Size([50260, 768]).\nRetrying with ignore_mismatched_sizes=True ...\nâœ… Model ready for generation!\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://3c3039c59c49ee30a5.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://3c3039c59c49ee30a5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null}]}