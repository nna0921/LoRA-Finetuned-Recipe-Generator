{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5093016,"sourceType":"datasetVersion","datasetId":2957522}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n!pip install transformers datasets accelerate gradio -q\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-02T16:55:43.063542Z","iopub.execute_input":"2025-11-02T16:55:43.064094Z","iopub.status.idle":"2025-11-02T16:55:47.586442Z","shell.execute_reply.started":"2025-11-02T16:55:43.064064Z","shell.execute_reply":"2025-11-02T16:55:47.585421Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Sun Nov  2 16:55:43 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   61C    P0             30W /   70W |    2281MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   58C    P0             28W /   70W |     397MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nimport re\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T16:55:47.588553Z","iopub.execute_input":"2025-11-02T16:55:47.588810Z","iopub.status.idle":"2025-11-02T16:55:47.593215Z","shell.execute_reply.started":"2025-11-02T16:55:47.588790Z","shell.execute_reply":"2025-11-02T16:55:47.592436Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/3a2mext/3A2M_EXTENDED.csv\")\nprint(df.columns)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T16:55:47.594115Z","iopub.execute_input":"2025-11-02T16:55:47.594681Z","iopub.status.idle":"2025-11-02T16:56:23.625295Z","shell.execute_reply.started":"2025-11-02T16:55:47.594654Z","shell.execute_reply":"2025-11-02T16:56:23.624624Z"}},"outputs":[{"name":"stdout","text":"Index(['title', 'NER', 'Extended_NER', 'genre', 'label', 'directions'], dtype='object')\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                         title  \\\n0                 \\t Arugula Pomegranate Salad   \n1               \\t Black Bean And Turkey Chili   \n2               \\t Finger Lickin' Tofu Nuggets   \n3  \\t Jerk Beef Stew With Carrots And Tomatoes   \n4                \\t Pomegranate Couscous Salad   \n\n                                                 NER  \\\n0  [\"baby spinach\", \"baby arugula\", \"pomegranate ...   \n1  [\"olive oil\", \"yellow onion\", \"garlic\", \"groun...   \n2  [\"extra firm\", \"almond flour\", \"nutritional ye...   \n3  [\"olive oil\", \"boneless beef chuck\", \"onion\", ...   \n4  [\"pomegranate arils\", \"whole wheat couscous\", ...   \n\n                                        Extended_NER       genre  label  \\\n0  ['alfalfa sprouts', 'baby spinach', 'baby arug...  vegetables      4   \n1  ['one', 'yellow onion', 'tomato paste', 'about...       sides      8   \n2  ['extra firm', '2', 'coconut oil', 'almond flo...      nonveg      3   \n3  ['boneless beef chuck', '2', 'Saute', 'onion',...  vegetables      4   \n4  ['whole wheat couscous', '10 minutes', 'lemon ...  vegetables      4   \n\n                                          directions  \n0  [\"Toss together spinach and arugula, then plac...  \n1  [\"Dice the onion and mince the garlic. Add the...  \n2  [\"Wrap the tofu in a clean tea towel and press...  \n3  [\"Preheat oven to 350 degrees F.\", \"Heat the o...  \n4  [\"Place couscous in a bowl with 11/2 cups of h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>NER</th>\n      <th>Extended_NER</th>\n      <th>genre</th>\n      <th>label</th>\n      <th>directions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\t Arugula Pomegranate Salad</td>\n      <td>[\"baby spinach\", \"baby arugula\", \"pomegranate ...</td>\n      <td>['alfalfa sprouts', 'baby spinach', 'baby arug...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Toss together spinach and arugula, then plac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\t Black Bean And Turkey Chili</td>\n      <td>[\"olive oil\", \"yellow onion\", \"garlic\", \"groun...</td>\n      <td>['one', 'yellow onion', 'tomato paste', 'about...</td>\n      <td>sides</td>\n      <td>8</td>\n      <td>[\"Dice the onion and mince the garlic. Add the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\t Finger Lickin' Tofu Nuggets</td>\n      <td>[\"extra firm\", \"almond flour\", \"nutritional ye...</td>\n      <td>['extra firm', '2', 'coconut oil', 'almond flo...</td>\n      <td>nonveg</td>\n      <td>3</td>\n      <td>[\"Wrap the tofu in a clean tea towel and press...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\t Jerk Beef Stew With Carrots And Tomatoes</td>\n      <td>[\"olive oil\", \"boneless beef chuck\", \"onion\", ...</td>\n      <td>['boneless beef chuck', '2', 'Saute', 'onion',...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Preheat oven to 350 degrees F.\", \"Heat the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\t Pomegranate Couscous Salad</td>\n      <td>[\"pomegranate arils\", \"whole wheat couscous\", ...</td>\n      <td>['whole wheat couscous', '10 minutes', 'lemon ...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Place couscous in a bowl with 11/2 cups of h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# ====================================================\n# 1. Basic Cleaning and Column Normalization\n# ====================================================\ndf.columns = df.columns.str.strip().str.lower()\n\n# Remove completely empty rows\ndf.dropna(how='all', inplace=True)\n\n# ====================================================\n# 2. Drop duplicate rows safely (Option 1)\n# ====================================================\ndf_str = df.copy()\nfor col in [\"ner\", \"extended_ner\", \"directions\"]:\n    if col in df_str.columns:\n        df_str[col] = df_str[col].astype(str)  # Convert lists to strings for deduplication\n\ndf = df.loc[~df_str.duplicated()].copy()\nprint(f\"✅ Duplicates removed, current shape: {df.shape}\")\n\n# ====================================================\n# 3. Clean list-like columns safely\n# ====================================================\ndef clean_list_column(col):\n    cleaned = []\n    for val in col:\n        # Case 1: Already a list/tuple — keep it as is\n        if isinstance(val, (list, tuple)):\n            cleaned.append(list(val))\n            continue\n\n        # Case 2: Empty or NaN\n        if pd.isna(val):\n            cleaned.append([])\n            continue\n\n        # Case 3: Try parsing JSON-like strings\n        try:\n            parsed = json.loads(str(val).replace(\"'\", '\"'))\n            if isinstance(parsed, list):\n                cleaned.append(parsed)\n            else:\n                cleaned.append([str(parsed)])\n        except:\n            # Case 4: Fallback to comma-split\n            cleaned.append([x.strip() for x in str(val).split(\",\")])\n    return cleaned\n\n\nfor col in [\"ner\", \"extended_ner\", \"directions\"]:\n    if col in df.columns:\n        df[col] = clean_list_column(df[col])\n\n# Drop rows missing essential data\nif \"title\" in df.columns and \"directions\" in df.columns:\n    df.dropna(subset=[\"title\", \"directions\"], inplace=True)\n\nprint(f\"✅ After cleaning list-like columns: {df.shape}\")\n\n# ====================================================\n# 4. Skip Genre Normalization (as requested)\n# ====================================================\nif \"genre\" not in df.columns:\n    df[\"genre\"] = \"unknown\"\n\n# ====================================================\n# 5. Add Derived Columns\n# ====================================================\ndf[\"ingredient_count\"] = df[\"ner\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\ndf[\"direction_length\"] = df[\"directions\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n\n# Remove rows with no ingredients or directions\ndf = df[(df[\"ingredient_count\"] > 0) & (df[\"direction_length\"] > 0)]\n\n# Drop duplicates based on title + genre\ndf.drop_duplicates(subset=[\"title\", \"genre\"], inplace=True)\n\n# Reset index\ndf.reset_index(drop=True, inplace=True)\n\nprint(f\"✅ Final cleaned dataset shape: {df.shape}\")\n\n# ====================================================\n# 6. Display Random Samples\n# ====================================================\nprint(\"\\n=== Random Sample of Cleaned Recipes ===\\n\")\nsample_df = df.sample(min(10, len(df)), random_state=42)[[\"title\", \"genre\", \"ner\", \"directions\"]]\n\nfor i, row in sample_df.iterrows():\n    print(f\"Recipe {i+1}: {row['title']}\")\n    print(f\"Genre: {row['genre']}\")\n    print(f\"Ingredients ({len(row['ner'])}): {', '.join(row['ner'][:10])}...\")\n    print(f\"First 2 Steps: {row['directions'][:2]}\")\n    print(\"-\" * 100)\n\n# ====================================================\n# 7. Summary Stats\n# ====================================================\nprint(\"\\n=== Dataset Statistics ===\")\nprint(f\"Average number of ingredients: {df['ingredient_count'].mean():.2f}\")\nprint(f\"Average number of directions: {df['direction_length'].mean():.2f}\")\nprint(f\"Unique genres: {df['genre'].nunique()} -> {sorted(df['genre'].unique().tolist())}\")\n\n# ====================================================\n# 8. Save Cleaned CSV\n# ====================================================\noutput_path = \"cleaned_recipes.csv\"\ndf.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\nprint(f\"\\n✅ Cleaned dataset saved as: {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T16:56:23.668049Z","iopub.execute_input":"2025-11-02T16:56:23.668267Z","iopub.status.idle":"2025-11-02T16:58:16.640061Z","shell.execute_reply.started":"2025-11-02T16:56:23.668251Z","shell.execute_reply":"2025-11-02T16:58:16.639204Z"}},"outputs":[{"name":"stdout","text":"✅ Duplicates removed, current shape: (2230998, 6)\n✅ After cleaning list-like columns: (2230997, 6)\n✅ Final cleaned dataset shape: (1314993, 8)\n\n=== Random Sample of Cleaned Recipes ===\n\nRecipe 622937: Honey-Dijon Salad with Shrimp\nGenre: vegetables\nIngredients (11): [\"torn romaine lettuce leaves\", \"shrimp\", \"mushrooms\", \"carrots\", \"egg substitute\", \"corn oil\", \"white wine vinegar\", \"Mustard\", \"honey\", \"croutons\"...\nFirst 2 Steps: ['[\"Mix lettuce', 'shrimp']\n----------------------------------------------------------------------------------------------------\nRecipe 666671: Kaessuppe\nGenre: fusion\nIngredients (7): [\"butter\", \"flour\", \"emmentaler cheese\", \"beef stock\", \"egg yolks\", \"sugar\", \"bread\"]...\nFirst 2 Steps: ['[\"Melt the butter and stir in the flour.\"', '\"Add meat broth.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 284614: Chimichurri Muy Perfecto\nGenre: fusion\nIngredients (10): [\"flat-leaf Italian parsley\", \"olive oil\", \"red wine vinegar\", \"oregano\", \"ground cumin\", \"kosher salt\", \"garlic\", \"hot sauce\", \"red pepper\", \"lemon juice\"]...\nFirst 2 Steps: ['[\"Combine all ingredients in a food processor', 'and process until the parsley is finely minced.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 824173: None Such Cinnamon Raisin Biscotti\nGenre: sides\nIngredients (8): [\"sugar\", \"butter\", \"eggs\", \"vanilla\", \"flour\", \"baking powder\", \"ground cinnamon\", \"condensed mincemeat\"]...\nFirst 2 Steps: ['[\"Preheat oven to 325 degrees F. In large bowl', 'beat sugar']\n----------------------------------------------------------------------------------------------------\nRecipe 40233: Apple Cider Chicken With Wild Rice\nGenre: sides\nIngredients (15): [\"Chicken\", \"skinless\", \"salt\", \"canola oil\", \"shallots\", \"apple cider vinegar\", \"sweet apple cider\", \"apple\", \"sweet apple\", \"chicken broth\"...\nFirst 2 Steps: ['[\"Season chicken cutlets with salt and pepper.\"', '\"Get a skillet very hot. Once it is hot']\n----------------------------------------------------------------------------------------------------\nRecipe 1235434: Trout Kottwitz\nGenre: Fusion\nIngredients (9): [\"butter\", \"trout\", \"artichoke bottoms\", \"mushrooms\", \"salt\", \"pepper\", \"Brown Sauce\", \"lemon juice\", \"butter\"]...\nFirst 2 Steps: ['Melt 5 tablespoons butter in a large heavy skillet add trout artichokes and mushrooms and cook 7 to 8 minutes over medium heat or until fish flakes easily with a fork. Sprinkle with salt and pepper while cooking. Remove fish and vegetables to heated plates or keep warm in low oven. Combine Brown Sauce lemon juice and the 2 cups butter mix with a wire whisk and cook over low heat until heated through. To serve ladle about 1/4 cup sauce over each fillet. Makes 8 servings.']\n----------------------------------------------------------------------------------------------------\nRecipe 1024441: Salmon With A Lemon Teriyaki Glaze\nGenre: drinks\nIngredients (8): [\"soy sauce\", \"sugar\", \"rice wine\", \"garlic\", \"ginger\", \"lemon\", \"mustard\", \"salmon\"]...\nFirst 2 Steps: ['[\"In a pot', 'combine the soy sauce']\n----------------------------------------------------------------------------------------------------\nRecipe 1249204: Ukrainian Fruit Vodka (Varenukha)\nGenre: vegetables\nIngredients (11): [\"dried apples\", \"cherries\", \"pear\", \"vodka\", \"honey\", \"ground ginger\", \"ground cinnamon\", \"ground cloves\", \"black pepper\", \"bay leaf\"...\nFirst 2 Steps: ['[\"Place each of the four fruits in a separate bowl.\"', '\"Cover the fruits with the vodka.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 831210: Oatmeal Cookies With White Chocolate Chips and Raisins\nGenre: cereal\nIngredients (12): [\"unsalted butter\", \"sugar\", \"brown sugar\", \"egg\", \"vanilla\", \"flour\", \"rolled oats\", \"baking soda\", \"cinnamon\", \"salt\"...\nFirst 2 Steps: ['[\"Beat the butter', 'granulated sugar and brown sugar in a bowl with a mixer on medium speed until fluffy.\"']\n----------------------------------------------------------------------------------------------------\nRecipe 415643: Dill Meatballs With Cranberry Sauce\nGenre: sides\nIngredients (16): [\"butter\", \"shallot\", \"frozen cranberries\", \"brown sugar\", \"cranberry juice\", \"rosemary\", \"red wine vinegar\", \"cornstarch\", \"sour cream\", \"milk\"...\nFirst 2 Steps: ['[\"Melt the butter in a saucepan over medium-low heat. Add the shallot and cook for 2-3 mins until softened. Add the cranberries and brown sugar and cook for 7-10 mins until the cranberries begin to pop. Stir in the cranberry juice', 'rosemary and vinegar. In a cup']\n----------------------------------------------------------------------------------------------------\n\n=== Dataset Statistics ===\nAverage number of ingredients: 8.93\nAverage number of directions: 12.84\nUnique genres: 10 -> ['Fusion', 'bakery', 'cereal', 'drinks', 'fastfood', 'fusion', 'meal', 'nonveg', 'sides', 'vegetables']\n\n✅ Cleaned dataset saved as: cleaned_recipes.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport ast\nimport re\n\n# --- Robust cleaning function ---\ndef clean_recipe(row):\n    # --- Helper to remove brackets, quotes, and fix unicode ---\n    def clean_text(text):\n        if not text:\n            return \"\"\n        text = str(text)\n        # Fix degree/Fahrenheit symbols\n        text = text.replace(\"\\\\u00b0\", \"°\")  # Unicode ° symbol\n        text = text.replace(\"\\\\u00b0F\", \"°F\")\n        text = text.replace(\"\\\\u00b0C\", \"°C\")\n        # Remove all [ ] { } ' \" ` and extra spaces\n        text = re.sub(r\"[\\[\\]{}'\\\"`]\", \"\", text)\n        text = re.sub(r\"\\s+\", \" \", text)\n        return text.strip()\n\n    # --- Ingredients ---\n    ner_val = row.get(\"ner\", [])\n    if isinstance(ner_val, str):\n        try:\n            ner_val = ast.literal_eval(ner_val)\n        except:\n            ner_val = [ner_val]\n    ingredients = \", \".join([clean_text(i) for i in ner_val if str(i).strip()])\n\n    # --- Directions ---\n    dir_val = row.get(\"directions\", [])\n    if isinstance(dir_val, str):\n        try:\n            dir_val = ast.literal_eval(dir_val)\n        except:\n            dir_val = [dir_val]\n    # Flatten nested lists\n    flat_dirs = []\n    for d in dir_val:\n        if isinstance(d, (list, tuple)):\n            flat_dirs.extend(d)\n        else:\n            flat_dirs.append(d)\n    directions = \" \".join([clean_text(d) for d in flat_dirs if str(d).strip()])\n\n    # --- Title ---\n    title = clean_text(row.get(\"title\", \"\"))\n\n    # --- Compose final recipe ---\n    return f\"<|startofrecipe|> Title: {title}\\nIngredients: {ingredients}\\nDirections: {directions} <|endofrecipe|>\"\n\n# --- Apply cleaning ---\ndf['text'] = df.apply(clean_recipe, axis=1)\n\n# --- Remove duplicates ---\ndf.drop_duplicates(subset='text', inplace=True)\n\n# --- Check remaining brackets ---\nremaining_brackets = df['text'].str.contains(r'[\\[\\]]').sum()\nprint(f\"Remaining brackets: {remaining_brackets}\")  # Should be 0\n\n# --- Show first 15 examples ---\nfor i in range(min(15, len(df))):\n    print(f\"Example {i+1}:\\n{df['text'].iloc[i]}\\n{'-'*80}\")\n\n# --- Save cleaned dataset to CSV ---\noutput_path = \"cleaned_recipes_final.csv\"\ndf.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\nprint(f\"\\n✅ Cleaned dataset saved as: {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T16:58:16.641044Z","iopub.execute_input":"2025-11-02T16:58:16.641328Z","iopub.status.idle":"2025-11-02T17:02:01.733596Z","shell.execute_reply.started":"2025-11-02T16:58:16.641310Z","shell.execute_reply":"2025-11-02T17:02:01.732651Z"}},"outputs":[{"name":"stdout","text":"Remaining brackets: 0\nExample 1:\n<|startofrecipe|> Title: Arugula Pomegranate Salad\nIngredients: baby spinach, baby arugula, pomegranate arils, persimmon, alfalfa sprouts\nDirections: Toss together spinach and arugula then place in your serving bowl. Remove the stem and leaves of the persimmon then slice into thin wedges. Arrange the persimmon on top of the spinach and arugula. Garnish with pomegranate arils and alfalfa sprouts. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 2:\n<|startofrecipe|> Title: Black Bean And Turkey Chili\nIngredients: olive oil, yellow onion, garlic, ground turkey, black beans, tomatoes, tomato paste, chili powder, cumin, paprika, oregano, salt\nDirections: Dice the onion and mince the garlic. Add the onion and garlic to a large stock pot with one tablespoon of olive oil and cook over medium-low heat just until softened. Add the ground turkey to the pot and continue to saute until the turkey is cooked through. Break the turkey up into small crumbles as it cooks. Add the all of the remaining ingredients. Stir to combine. Let the chili simmer for about 10 minutes to let the flavors blend and help the liquid thicken slightly. Add salt to taste. Enjoy with your favorite chili toppings! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 3:\n<|startofrecipe|> Title: Finger Lickin Tofu Nuggets\nIngredients: extra firm, almond flour, nutritional yeast, garlic, unsweetened almond milk, coconut oil\nDirections: Wrap the tofu in a clean tea towel and press to remove excess water. Combine all other ingredients in a bowl except for the almond milk. Slowly add the almond milk and stir until you get a paste. Cut the tofu into bite-sized pieces. You can do strips or nuggets if you like but the smaller bites mean more of the yummy coating. Plus it reminds me of popcorn shrimp or chicken! Roll the tofu bites around in the coating until theyre well... coated. Over medium heat heat the oil in a frying pan. Add tofu bites in a single layer and brown them on 2 sides. Serve with Sriracha or other favourite dipping sauce. Enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 4:\n<|startofrecipe|> Title: Jerk Beef Stew With Carrots And Tomatoes\nIngredients: olive oil, boneless beef chuck, onion, Progresso, jerk sauce, allspice, cinnamon, thyme, brown rice\nDirections: Preheat oven to 350 degrees F. Heat the olive oil in a Dutch oven over medium-high heat. Add the beef and let it brown on each side (about 5 minutes/side). Stir the beef and add the onions carrots and garlic. Saute for 3 minutes or until the onions are translucent. Cover the Dutch oven and place it in the oven. Cook for 1 hour to 1 1/2 hours or until the beef falls apart easily when shredded 2 forks. Take the stew out of the oven. Remove the bay leaves. If the stew is too thin reduce over high heat on the stovetop. Serve over the brown rice or quinoa and with a side of greens. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 5:\n<|startofrecipe|> Title: Pomegranate Couscous Salad\nIngredients: pomegranate arils, whole wheat couscous, extra virgin olive oil, cilantro, cranberries, lemon juice\nDirections: Place couscous in a bowl with 11/2 cups of hot water. Cover bowl with plastic wrap and let set for 10 minutes. Add the olive oil and toss gently. Add vegetables and cilantro or parsley; mix to combine. Add cranberries arils and lemon juice; salt and pepper to taste. Gently toss and enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 6:\n<|startofrecipe|> Title: Raclette Hasselback Potatoes\nIngredients: potatoes, olive oil, butter, salt Generous, raclette cheese, paprika\nDirections: Preheat oven to 425°F (220°C). Melt the butter in a small saucepan and pour it in a large bowl. Mix with the olive oil and season with salt pepper ground coriander seeds dry aromatic herbs ... Cut the potatoes into thin slices without completely detaching those slices from the potato so that they stay tied together. Baste the potatoes one by one with the butter and olive oil mixture opening gently each slice so that the fat gets between each and place them in a large oven dish. First bake the potatoes for 30 minutes. Then take the dish out of the oven and coat the potatoes with the cooking sauce or the rest of the butter and olive oil mixture. Bake the potatoes for 45 more minutes until they are golden tender and opened. In the meantime cut the raclette cheese into pieces small enough to be placed between each slice of the potatoes. Take out the dish from the oven when the potatoes are cooked and place the pieces of cheese between each slice of the potatoes until there is no more. If you want you can alternate the pieces of cheese with other ingredients such as ham pepper broccoli or any other ingredient you fancy. Place the dish with the stuffed potatoes in oven on \\grill\\ mode and bake for 5 more minutes. Add more seasoning if you like: paprika aromatic herbs ... and serve very hot. Eaten with a salad or as a side dish with a meat these potatoes are delicious.\\n\\nBon appetit! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 7:\n<|startofrecipe|> Title: The Black Pear Shim\nIngredients: Black Balsam, Juice(I, Lemon Juice, Syrup\nDirections: Shake all ingredients to chill and dilute. Strain into a martini glass and garnish with a lemon twist. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 8:\n<|startofrecipe|> Title: Mixed Mashed Muffins\nIngredients: butter, egg, brown sugar, honey crunch peanut butter, vanilla, baking soda, granola Kimberly, water\nDirections: Combine flour brown sugar salt and baking soda and Kimberlys Granola in large bowl set aside. Cream together egg vanilla peanut butter milk or water until smooth. Gradually add soft mixture to flour brown sugar salt baking soda and Kimberlys Granola until totally combined. Spoon into muffin tin and bake in preheated 350 degree oven for 20-25 minutes Remove from oven and remove from muffin tin to cool on cooling rack. Serve warm and Enjoy! <3 <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 9:\n<|startofrecipe|> Title: Penut Butter Fudge Delight\nIngredients: white sugar, milk, vanilla, butter, milk, butter\nDirections: In a medium saucepan over medium heat combine sugar butter and milk. Bring to a boil. stir and boil for 7 minutes. remove from sauce pan and add peanut butter and vanilla extract if not melting put back on stove and bring to a low boil grease a 9 bt 13 baking dish pour into the dish and voila leave over night and cut into cubes enjoy !!!!!!!!!!!!!!!!!!! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 10:\n<|startofrecipe|> Title: Kevin’S Insane Bacon Cheese Dip\nIngredients: bacon, cream cheese, mayo, swiss cheese, cheddar cheese, green onion, butter crackers\nDirections: Cook bacon. Drain crumble. Mix the cream cheese with mayo until smooth. Stir in Swiss & Cheddar cheese onions and bacon. Place bowl in microwave and cook 2 minutes. Pull it out and stir it up good. Microwave another 2 or 3 minutes more. Sprinkle crushed crackers on top. Serve it up warm with crackers! (Yep... yet another one that I stole off the net... but severely modified it!!!) <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 11:\n<|startofrecipe|> Title: ~Raspberry Butterfly Cupcakes~\nIngredients: sugar, margarine, eggs, flour, tspbaking power, vanilla, raspberry\nDirections: Preheat the oven to 190*c/375*F/ Gas Mark 5. line one or two bun trays with 12-14 cases depending on the depth of the holes. Places all the cupcake ingredients in a large bowl and beat with the electric mixer for about 2 minutes until smooth. Fill the paper cases halfway up the mixture. Bake for about 15 minutes until firm risen and golden. Remove to a wire rack and cool it. When its cool cut a small circle out of the top of each cupcake and then cut the circles in half like a wings shape. Fill each cupcake with a teaspoon of raspberry jam. replace the wings at an angle and top each with a fresh reaspberry. dust lightly with icing sugar and serve immediately. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 12:\n<|startofrecipe|> Title: Bacon Lovers Ranch Mashed Potatoes\nIngredients: potatoes, butter, mayo, sour cream, bacon Party\nDirections: : In a pot cube desired amount of potatoes or use instant potatoes. Cook until the potatoes are tender drain and then mash. Add 1/2 cup butter 3 tbs. mayonnaise 1 cup sour cream and 1 package dip mix. Whip the added ingredients into the cooked/mashed potatoes. Serve and enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 13:\n<|startofrecipe|> Title: 20-Minute Kale And Quinoa Bowl\nIngredients: water, quinoa, kale washed, lemon, scallions, olive oil, almonds, goat cheese, salt\nDirections: Bring 2 cups water to boil in a covered pot with a large pinch of salt. Add quinoa lower heat to simmer cover and simmer 10 minutes. After 8-10 minutes when theres still some water left add the chopped kale... Cover let simmer for 5 minutes then turn off the heat and let it sit for 5 minutes covered. Combine half of lemon juice with zest scallions olive oil nuts and cheese into a bowl Put quinoa kale mixture in a bowl. add one bowl to another and mix. <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 14:\n<|startofrecipe|> Title: Busy Morning Corn Muffins\nIngredients: flour, cornmeal, sugar, salt, baking powder, milk regular, butter, eggs\nDirections: Equipment youll need ready:\\n\\n2 bowls (1 for dry 1 for wet)\\nliquid and dry measure cups\\nmeasuring spoons\\nmuffin tins to make 12 regular sized muffins (not the huge muffin tins)\\ncooling rack\\nwhisk (if you have one)\\nwooden spoon\\nrubber spatula\\ncupcake papers (or grease the muffin tin very well)\\n\\nPreheat oven to 500° Bowl 1 - Dry:\\n\\nMix flour cornmeal sugar salt and baking powder whisking till all ingredient are completely mixed so ingredients are evenly dispersed. I love using the whisk for this. Bowl 2 -Wet:\\n\\nThoroughly blend eggs milk and oil together. Add wet to dry bowl just mix well enough so nothing is dry sticking to the sides of the bowl but dont beat. Use a scraper of wooden spoon to mix thoroughly - over mixing (no electric beaters please) will make for tough muffins! Evenly fill the muffin tins. Using a scoop* helps with aim into the cup part or even a dry measure 1/2 cup size would be beneficial so they are all the same size which makes for nicer presentation and more even baking. Note: I find it easier to wipe batter that didnt make it into the cups before baking is easier than scrubbing it off later. Pop the tin into the oven and as soon as you close the door LOWER the oven temperature to 400° bake 18-20 minutes. This super hot then lower method will allow the muffins get that nice domed look. Cool on a wire rack for a few minutes. Enjoy! <|endofrecipe|>\n--------------------------------------------------------------------------------\nExample 15:\n<|startofrecipe|> Title: Oatmeal\nIngredients: Oats, water, milk, cinnamon, put\nDirections: cook it for 15 or 20 minutes get it out <|endofrecipe|>\n--------------------------------------------------------------------------------\n\n✅ Cleaned dataset saved as: cleaned_recipes_final.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Check if any brackets remain\ndf['text'].str.contains(r'[\\[\\]]').sum()  # Should be 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:02:01.734507Z","iopub.execute_input":"2025-11-02T17:02:01.734803Z","iopub.status.idle":"2025-11-02T17:02:10.203502Z","shell.execute_reply.started":"2025-11-02T17:02:01.734767Z","shell.execute_reply":"2025-11-02T17:02:10.202689Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# one-time installs (run in a notebook cell)\n!pip install -q transformers datasets accelerate bitsandbytes peft evaluate sentencepiece gradio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:02:10.204368Z","iopub.execute_input":"2025-11-02T17:02:10.205063Z","iopub.status.idle":"2025-11-02T17:02:14.429096Z","shell.execute_reply.started":"2025-11-02T17:02:10.205037Z","shell.execute_reply":"2025-11-02T17:02:14.428094Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ==========================================================\n#  DISTILGPT2 RECIPE FINE-TUNING (LoRA + 4-bit + Tokenizer Integration)\n# ==========================================================\nimport os, gc, random\nimport pandas as pd\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    AutoConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\n\n# ---------------- CONFIG ----------------\nMODEL_NAME = \"distilgpt2\"      # smaller + faster than GPT-2\nCLEANED_CSV = \"cleaned_recipes_final.csv\"\nOUTPUT_DIR = \"/kaggle/working/gpt2_recipe_lora\"\nNUM_EPOCHS = 3                 # 3–5 sufficient per assignment\nPER_DEVICE_BATCH = 2\nGRAD_ACCUM = 8\nMAX_LENGTH = 512\nSEED = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\">>> Device: {DEVICE}\")\n\n# ---------------- REPRODUCIBILITY ----------------\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\nif DEVICE == \"cuda\":\n    torch.cuda.manual_seed_all(SEED)\n\n# ---------------- LOAD DATA ----------------\ndf = pd.read_csv(CLEANED_CSV, encoding=\"utf-8-sig\")\ndf = df[[\"text\"]].dropna().reset_index(drop=True)\nprint(\"Loaded samples:\", len(df))\n\ndataset = Dataset.from_pandas(df)\n\n# ---------------- TOKENIZER ----------------\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\nspecial_tokens = [\"<|startofrecipe|>\", \"<|endofrecipe|>\"]\ntokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\ntokenizer.pad_token = tokenizer.eos_token  # GPT2 has no pad token\n\ndef tokenize_batch(examples):\n    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH)\n\nprint(\"Tokenizing dataset...\")\ndataset = dataset.map(tokenize_batch, batched=True, remove_columns=[\"text\"], desc=\"Tokenizing\")\ndataset = dataset.train_test_split(test_size=0.1, seed=SEED)\ntrain_ds = dataset[\"train\"]\neval_ds  = dataset[\"test\"]\nprint(f\"Train size: {len(train_ds)}  |  Eval size: {len(eval_ds)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:02:14.430375Z","iopub.execute_input":"2025-11-02T17:02:14.430596Z","iopub.status.idle":"2025-11-02T17:08:03.744263Z","shell.execute_reply.started":"2025-11-02T17:02:14.430577Z","shell.execute_reply":"2025-11-02T17:08:03.743558Z"}},"outputs":[{"name":"stdout","text":">>> Device: cuda\nLoaded samples: 1314980\nTokenizing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/1314980 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b97f953a2d49b9b39a805b412cec32"}},"metadata":{}},{"name":"stdout","text":"Train size: 1183482  |  Eval size: 131498\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"load_4bit = torch.cuda.is_available()\nif load_4bit:\n    print(\">>> Using 4-bit quantization for efficiency\")\n    from transformers import BitsAndBytesConfig\n\n    quant_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\"\n    )\n\n    model = AutoModelForCausalLM.from_pretrained(\n        MODEL_NAME,\n        quantization_config=quant_config,\n        device_map={\"\": torch.cuda.current_device()}  # FIX: ensures model is on correct GPU\n    )\nelse:\n    print(\">>> Loading model normally (no 4-bit support detected)\")\n    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n\n# Resize embeddings for special tokens\ntry:\n    model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\nexcept TypeError:\n    model.resize_token_embeddings(len(tokenizer))\n\n# ---------------- APPLY LORA ----------------\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"c_attn\", \"q_proj\", \"v_proj\"]\n)\nmodel = get_peft_model(model, peft_config)\n\n# Freeze non-LoRA params\nfor n, p in model.named_parameters():\n    if \"lora\" not in n:\n        p.requires_grad = False\n\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\">>> Trainable params: {trainable_params:,} / {total_params:,}\")\n\n# ---------------- DATA COLLATOR ----------------\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n# ---------------- TRAINING ARGS ----------------\ntry:\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        num_train_epochs=NUM_EPOCHS,\n        per_device_train_batch_size=PER_DEVICE_BATCH,\n        per_device_eval_batch_size=PER_DEVICE_BATCH,\n        gradient_accumulation_steps=GRAD_ACCUM,\n        fp16=True,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        logging_strategy=\"steps\",\n        logging_steps=50,\n        learning_rate=5e-5,\n        weight_decay=0.01,\n        warmup_steps=50,\n        save_total_limit=2,\n        report_to=\"none\",\n        dataloader_num_workers=2,\n        optim=\"paged_adamw_32bit\"\n    )\n    print(\">>> TrainingArguments initialized successfully.\")\nexcept TypeError:\n    print(\">>> Transformer version fallback detected.\")\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        num_train_epochs=NUM_EPOCHS,\n        per_device_train_batch_size=PER_DEVICE_BATCH,\n        gradient_accumulation_steps=GRAD_ACCUM,\n        fp16=True,\n        logging_steps=50,\n        save_steps=500,\n        learning_rate=5e-5,\n        weight_decay=0.01,\n        warmup_steps=50,\n        report_to=\"none\"\n    )\n\n# ---------------- TRAINER ----------------\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\n# ---------------- TRAINING ----------------\nprint(\"\\n>>> Starting fine-tuning for\", NUM_EPOCHS, \"epochs...\")\ntrainer.train()\nprint(\">>> Training complete ✅\")\n\n# ---------------- SAVE MODEL ----------------\ntrainer.save_model(os.path.join(OUTPUT_DIR, \"final_checkpoint\"))\nmodel.save_pretrained(os.path.join(OUTPUT_DIR, \"lora_adapter\"))\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(\">>> Model + tokenizer saved to\", OUTPUT_DIR)\n\n# ---------------- GENERATE SAMPLE OUTPUT ----------------\nprint(\"\\n>>> Generating sample recipe for qualitative evaluation...\")\nprompt = \"<|startofrecipe|> Title: Creamy Mushroom Pasta\\nIngredients: mushroom, cream, garlic, pasta\\nDirections:\"\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)  # FIX: use model.device\n\ngeneration = model.generate(\n    input_ids,\n    max_length=200,\n    do_sample=True,\n    top_k=50,\n    top_p=0.95,\n    temperature=0.8,\n    num_return_sequences=1\n)\n\nprint(\"\\n=== SAMPLE GENERATION ===\\n\")\nprint(tokenizer.decode(generation[0], skip_special_tokens=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:17:46.468636Z","iopub.execute_input":"2025-11-02T17:17:46.469351Z","iopub.status.idle":"2025-11-02T17:18:11.260001Z","shell.execute_reply.started":"2025-11-02T17:17:46.469326Z","shell.execute_reply":"2025-11-02T17:18:11.258873Z"}},"outputs":[{"name":"stdout","text":">>> Using 4-bit quantization for efficiency\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/3923081453.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":">>> Trainable params: 147,456 / 60,827,904\n>>> Transformer version fallback detected.\n\n>>> Starting fine-tuning for 3 epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='61' max='110952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    61/110952 00:22 < 11:57:06, 2.58 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>27.257300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3923081453.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# ---------------- TRAINING ----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n>>> Starting fine-tuning for\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> Training complete ✅\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2204\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2206\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2207\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2546\u001b[0m                     )\n\u001b[1;32m   2547\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3795\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2572\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2574\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2575\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2576\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\n\n# Download the entire folder\nFileLinks(\"/kaggle/working/gpt2_recipe_lora/checkpoint-2000\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:16:17.827190Z","iopub.execute_input":"2025-11-02T17:16:17.827468Z","iopub.status.idle":"2025-11-02T17:16:17.834077Z","shell.execute_reply.started":"2025-11-02T17:16:17.827448Z","shell.execute_reply":"2025-11-02T17:16:17.833237Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/gpt2_recipe_lora/checkpoint-2000/\n  scheduler.pt\n  added_tokens.json\n  optimizer.pt\n  tokenizer_config.json\n  vocab.json\n  rng_state.pth\n  adapter_model.safetensors\n  adapter_config.json\n  trainer_state.json\n  scaler.pt\n  tokenizer.json\n  training_args.bin\n  README.md\n  merges.txt\n  special_tokens_map.json","text/html":"/kaggle/working/gpt2_recipe_lora/checkpoint-2000/<br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/scheduler.pt' target='_blank'>scheduler.pt</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/added_tokens.json' target='_blank'>added_tokens.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/optimizer.pt' target='_blank'>optimizer.pt</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/tokenizer_config.json' target='_blank'>tokenizer_config.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/vocab.json' target='_blank'>vocab.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/rng_state.pth' target='_blank'>rng_state.pth</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/adapter_model.safetensors' target='_blank'>adapter_model.safetensors</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/adapter_config.json' target='_blank'>adapter_config.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/trainer_state.json' target='_blank'>trainer_state.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/scaler.pt' target='_blank'>scaler.pt</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/tokenizer.json' target='_blank'>tokenizer.json</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/training_args.bin' target='_blank'>training_args.bin</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/README.md' target='_blank'>README.md</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/merges.txt' target='_blank'>merges.txt</a><br>\n&nbsp;&nbsp;<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000/special_tokens_map.json' target='_blank'>special_tokens_map.json</a><br>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":" import shutil\n\ncheckpoint_path = \"/kaggle/working/gpt2_recipe_lora/checkpoint-2000\"\nzip_path = \"/kaggle/working/gpt2_recipe_lora/checkpoint-2000.zip\"\n\nshutil.make_archive(checkpoint_path, 'zip', checkpoint_path)\nprint(\"✅ Checkpoint zipped at:\", zip_path)\n\n# Make it downloadable\nFileLink(zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:17:04.512439Z","iopub.execute_input":"2025-11-02T17:17:04.513033Z","iopub.status.idle":"2025-11-02T17:17:12.169408Z","shell.execute_reply.started":"2025-11-02T17:17:04.513009Z","shell.execute_reply":"2025-11-02T17:17:12.168609Z"}},"outputs":[{"name":"stdout","text":"✅ Checkpoint zipped at: /kaggle/working/gpt2_recipe_lora/checkpoint-2000.zip\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/gpt2_recipe_lora/checkpoint-2000.zip","text/html":"<a href='/kaggle/working/gpt2_recipe_lora/checkpoint-2000.zip' target='_blank'>/kaggle/working/gpt2_recipe_lora/checkpoint-2000.zip</a><br>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# ==========================================================\n#  GENERATE SAMPLE RECIPES FROM LoRA + 4-BIT CHECKPOINT (FIXED)\n# ==========================================================\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\n\n# ---------- PATHS ----------\nBASE_MODEL = \"distilgpt2\"\nCHECKPOINT_DIR = \"/kaggle/working/gpt2_recipe_lora/checkpoint-2000\"\n\n# ---------- DEVICE ----------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\">>> Using device: {DEVICE}\")\n\n# ---------- LOAD TOKENIZER ----------\ntokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_DIR)\ntokenizer.pad_token = tokenizer.eos_token\n\n# ---------- LOAD BASE MODEL ----------\nprint(\">>> Loading base model...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n    device_map=\"auto\"\n)\n\n# 🚨 Resize embeddings to match tokenizer (important fix)\nbase_model.resize_token_embeddings(len(tokenizer))\n\n# ---------- LOAD LoRA ADAPTER ----------\nprint(\">>> Loading fine-tuned LoRA adapter...\")\nmodel = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR)\nmodel = model.to(DEVICE)\nmodel.eval()\n\n# ---------- SAMPLE PROMPTS ----------\nprompts = [\n    \"<|startofrecipe|> Title: Creamy Mushroom Pasta\\nIngredients: mushroom, cream, garlic, pasta\\nDirections:\",\n    \"<|startofrecipe|> Title: Spicy Chicken Curry\\nIngredients: chicken, chili, onion, tomato, garlic\\nDirections:\",\n    \"<|startofrecipe|> Title: Chocolate Chip Cookies\\nIngredients: flour, sugar, butter, chocolate chips\\nDirections:\",\n    \"<|startofrecipe|> Title: Fresh Lemonade\\nIngredients: lemon, sugar, water, ice\\nDirections:\"\n]\n\n# ---------- GENERATION SETTINGS ----------\ngen_kwargs = dict(\n    max_new_tokens=150,\n    do_sample=True,\n    temperature=0.8,\n    top_p=0.95,\n    top_k=50,\n    pad_token_id=tokenizer.eos_token_id,\n)\n\n# ---------- GENERATE ----------\nprint(\"\\n>>> Generating sample recipes...\\n\")\nfor prompt in prompts:\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n    outputs = model.generate(input_ids, **gen_kwargs)\n    print(\"=\" * 70)\n    print(f\"Prompt:\\n{prompt}\\n\")\n    print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n    print(\"=\" * 70, \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:18:25.714306Z","iopub.execute_input":"2025-11-02T17:18:25.715011Z","iopub.status.idle":"2025-11-02T17:18:32.240045Z","shell.execute_reply.started":"2025-11-02T17:18:25.714989Z","shell.execute_reply":"2025-11-02T17:18:32.239374Z"}},"outputs":[{"name":"stdout","text":">>> Using device: cuda\n>>> Loading base model...\n","output_type":"stream"},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":">>> Loading fine-tuned LoRA adapter...\n\n>>> Generating sample recipes...\n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Creamy Mushroom Pasta\nIngredients: mushroom, cream, garlic, pasta\nDirections:\n\n<|startofrecipe|> Title: Creamy Mushroom Pasta\nIngredients: mushroom, cream, garlic, pasta\nDirections: Preheat oven to 350 degrees. In a large skillet over medium-high heat add mushrooms and garlic and cook until browned. In a medium heat combine mushrooms and garlic and cook until golden browned. Add mushrooms and cook for 5 minutes until mushrooms are golden browned and on top of mushrooms. Add mushrooms and cook until mushrooms are golden browned and on top of mushrooms. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes. In a large skillet heat and cook for 5 minutes. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes. Add mushrooms and cook for 5 minutes\n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Spicy Chicken Curry\nIngredients: chicken, chili, onion, tomato, garlic\nDirections:\n\n<|startofrecipe|> Title: Spicy Chicken Curry\nIngredients: chicken, chili, onion, tomato, garlic\nDirections: Combine chicken and onion in a bowl and mix well. Put chicken in a microwave and cook for 15 minutes. Cut chicken into 4 pieces. Place chicken in a bowl and mix well. Cover with the foil and cook until chicken is soft but not soft. Add chicken and cook for 15 minutes. Add chicken and cook for 15 minutes. Add chicken and cook for 15 minutes. Remove chicken from heat and stir well. Add chicken and cook for 15 minutes. Add onion and cook for 15 minutes. Add chicken and cook for 15 minutes. Stir in garlic and onions. Cook for 15 minutes. Add chili and cook for 15 minutes. Add onion and cook for 15 minutes. Stir in tomato and cook for 15<|endofrecipe|> chicken. Cut chicken into 1/2\n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Chocolate Chip Cookies\nIngredients: flour, sugar, butter, chocolate chips\nDirections:\n\n<|startofrecipe|> Title: Chocolate Chip Cookies\nIngredients: flour, sugar, butter, chocolate chips\nDirections: Combine flour, sugar and chocolate chips in a medium mixer until smooth and smooth. In a large bowl combine flour and chocolate chips and beat until smooth and smooth. In a bowl add sugar and chocolate chips and beat until smooth. In a bowl combine flour and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate chips and beat until smooth. In a large bowl mix sugar and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate chips and beat until smooth. In a small bowl mix sugar and chocolate\n====================================================================== \n\n======================================================================\nPrompt:\n<|startofrecipe|> Title: Fresh Lemonade\nIngredients: lemon, sugar, water, ice\nDirections:\n\n<|startofrecipe|> Title: Fresh Lemonade\nIngredients: lemon, sugar, water, ice\nDirections: Combine lemon, sugar water ice and ice. Combine lemon. Freeze lemonade and ice. Beat together lemon. Put lemon in ice. Mix well. Stir in lemon. Whisk in ice. Turn on lemon. Pour over lemon juice. Bake 3 to 4 hours. Makes 6 to 8 hours. <|endofrecipe|> 2 servings <|endofrecipe|> 4 servings <|endofrecipe|> 3 servings <|endofrecipe|> 2 servings <|endofrecipe|> 4 servings   <|endofrecipe|> 2 servings                                                                \n====================================================================== \n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# ==========================================================\n# 🍳 Gradio App for LoRA-Finetuned DistilGPT2 (Recipe Generator)\n# ==========================================================\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\nimport gradio as gr\n\n# ---------- Paths ----------\nBASE_MODEL = \"distilgpt2\"\nCHECKPOINT_DIR = \"/kaggle/working/gpt2_recipe_lora/checkpoint-2000\"  # your LoRA adapter path\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ---------- Load Tokenizer ----------\nprint(\">>> Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\nspecial_tokens = {\n    \"pad_token\": \"<|pad|>\",\n    \"bos_token\": \"<|startofrecipe|>\",\n    \"eos_token\": \"<|endofrecipe|>\"\n}\ntokenizer.add_special_tokens(special_tokens)\n\n# ---------- Load Base Model ----------\nprint(\">>> Loading base model...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n)\nbase_model.resize_token_embeddings(len(tokenizer))\n\n# ---------- Load LoRA Adapter ----------\nprint(\">>> Loading LoRA fine-tuned adapter...\")\ntry:\n    model = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR)\n    print(\"✅ LoRA adapter loaded successfully!\")\nexcept Exception as e:\n    print(f\"⚠️ Adapter load issue: {e}\")\n    print(\"Retrying with ignore_mismatched_sizes=True ...\")\n    model = PeftModel.from_pretrained(base_model, CHECKPOINT_DIR, ignore_mismatched_sizes=True)\n\nmodel = model.to(DEVICE)\nmodel.eval()\n\nprint(\"✅ Model ready for generation!\")\n\n# ---------- Generation Function ----------\ndef generate_recipe(title, ingredients, max_length=200, temperature=0.8, top_p=0.9):\n    prompt = f\"<|startofrecipe|> Title: {title}\\nIngredients: {ingredients}\\nDirections:\"\n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            max_length=max_length,\n            do_sample=True,\n            temperature=temperature,\n            top_p=top_p,\n            pad_token_id=tokenizer.eos_token_id\n        )\n\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    recipe = generated_text.replace(prompt, \"\").strip()\n    return recipe\n\n# ---------- Gradio Interface ----------\ndemo = gr.Interface(\n    fn=generate_recipe,\n    inputs=[\n        gr.Textbox(label=\"Recipe Title\", placeholder=\"Creamy Mushroom Pasta\"),\n        gr.Textbox(label=\"Ingredients (comma-separated)\", placeholder=\"mushroom, cream, garlic, pasta\"),\n        gr.Slider(50, 400, value=200, step=10, label=\"Max Length\"),\n        gr.Slider(0.5, 1.2, value=0.8, step=0.05, label=\"Temperature\"),\n        gr.Slider(0.6, 1.0, value=0.9, step=0.05, label=\"Top-p\"),\n    ],\n    outputs=gr.Textbox(label=\"Generated Recipe Directions\"),\n    title=\"🍳 LoRA-Finetuned Recipe Generator\",\n    description=\"Generate creative cooking directions using a LoRA-finetuned DistilGPT2 model.\",\n    examples=[\n        [\"Garlic Butter Shrimp\", \"shrimp, garlic, butter, lemon, parsley\"],\n        [\"Pancakes\", \"flour, milk, egg, sugar, butter, baking powder\"],\n        [\"Spaghetti Aglio e Olio\", \"spaghetti, garlic, olive oil, chili flakes, parsley\"]\n    ]\n)\n\ndemo.launch(debug=True, share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T17:19:04.450589Z","iopub.execute_input":"2025-11-02T17:19:04.450884Z"}},"outputs":[{"name":"stdout","text":">>> Loading tokenizer...\n>>> Loading base model...\n>>> Loading LoRA fine-tuned adapter...\n⚠️ Adapter load issue: Error(s) in loading state_dict for PeftModelForCausalLM:\n\tsize mismatch for base_model.model.transformer.wte.weight: copying a param with shape torch.Size([50259, 768]) from checkpoint, the shape in current model is torch.Size([50260, 768]).\n\tsize mismatch for base_model.model.lm_head.weight: copying a param with shape torch.Size([50259, 768]) from checkpoint, the shape in current model is torch.Size([50260, 768]).\nRetrying with ignore_mismatched_sizes=True ...\n✅ Model ready for generation!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:477: UserWarning: Some weights of PeftModelForCausalLM were not initialized from the model checkpoint and are being ignored because you passed `ignore_mismatched_sizes=True`: - base_model.model.lm_head.weight: found shape torch.Size([50259, 768]) in the checkpoint and torch.Size([50260, 768]) in the model instantiated\n- base_model.model.transformer.wte.weight: found shape torch.Size([50259, 768]) in the checkpoint and torch.Size([50260, 768]) in the model instantiated.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://357c073fe9352b950f.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://357c073fe9352b950f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null}]}